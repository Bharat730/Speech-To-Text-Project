### **Script Name: `GitAI4MD.py`**

This script uses the NVIDIA NeMo toolkit to transcribe a sample of Hindi audio files. It sources the audio from a dataset provided by AI4Bharat on the Hugging Face Hub, saves local copies of the audio files, and then creates a text file for each transcription.

**Important Note:** This script performs high-quality **transcription only**. It does not perform speaker diarization or translation.

-----

### \#\# 1. Libraries and Installation

This script uses several advanced libraries for speech recognition. You can install them by running the following commands in your terminal. Note that `nemo_toolkit` can be a large and complex installation.

```powershell
pip install nemo_toolkit[asr]
pip install datasets
pip install soundfile librosa
```

#### **What Each Library Does:**

  * **`os` & `shutil`:** Built-in Python libraries used for interacting with the file system, such as creating and deleting folders.
  * **`pathlib`:** A modern, built-in Python library for handling file and folder paths in a way that works reliably across different operating systems.
  * **`nemo.collections.asr` (`nemo_toolkit`):** This is the core library from NVIDIA for speech recognition. It contains the powerful MahaDhwani model (`stt_hi_conformer_ctc_large`) that performs the transcription.
  * **`datasets`:** A library from Hugging Face that makes it easy to download and work with public datasets, including the Hindi audio samples used here.
  * **`soundfile`:** A helper library used to write the audio data from the dataset into a local `.wav` file.

-----

### \#\# 2. Code Explanation

  * **Lines 1-8: Imports**

      * Imports the necessary libraries listed above.

  * **Lines 10-14: Configuration**

      * `AUDIO_DIR`: Defines the name of the folder where local copies of the audio files will be saved (`MahaDhwani_audio`).
      * `TRANSCRIPTS_DIR`: Sets the name of the folder where the final text transcripts will be saved (`MahaDhwani_transcripts`).

  * **Lines 16-22: Setup**

      * The script first checks if the audio and transcript folders exist from a previous run and deletes them to ensure a clean start.
      * It then creates fresh, empty folders for the new run.

  * **Lines 25-29: Load the NeMo Model**

      * `asr_model = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(...)`: This is the key line that connects to the NVIDIA NGC model repository and downloads the pre-trained `stt_hi_conformer_ctc_large` model. The first time this runs, it will be a large download; subsequent runs will use the cached version.

  * **Lines 32-36: Load the Dataset**

      * `dataset = load_dataset("ai4bharat/IndicSUPERB", ...)`: This connects to the Hugging Face Hub and downloads the IndicSUPERB dataset, which is specifically designed for Indian languages.
      * `split="test[:5]"`: This tells the script to only download the first 5 audio samples from the test set for a quick demonstration.

  * **Lines 39-50: Prepare Audio Files**

      * The script loops through the 5 downloaded samples.
      * It extracts the raw audio data and saves each sample as a `.wav` file in the `MahaDhwani_audio` folder.
      * It collects the paths of these new local files into a list.

  * **Lines 53-55: Batch Transcription**

      * `transcriptions = asr_model.transcribe(...)`: This is the core transcription step. The script sends the list of all 5 local audio file paths to the NeMo model, which processes them in an efficient batch.

  * **Lines 58-64: Save Transcripts**

      * The script loops through the transcription results.
      * For each result, it creates a new `.txt` file in the `MahaDhwani_transcripts` folder and saves the transcribed text.

-----

### \#\# 3. Input Audio Source

  * **Source:** This script does not use your local files directly. It downloads 5 sample audio files from the **`ai4bharat/IndicSUPERB`** dataset on the Hugging Face Hub.
  * **Local Copy:** It saves a copy of these downloaded files as `.wav` files in the **`MahaDhwani_audio`** folder for processing.

-----

### \#\# 4. Output Transcripts

  * **Folder:** The script creates and saves all transcripts in a folder named **`MahaDhwani_transcripts`**.
  * **File Format:** Each transcript is saved as a separate `.txt` file, named sequentially (e.g., `hindi_transcript_0.txt`, `hindi_transcript_1.txt`, etc.).
  * **Content:** Each file contains only the Hindi transcription generated by the MahaDhwani model.