### **Script Name: `STTHindiDataset.py`**

This script uses OpenAI's Whisper model to perform both transcription and translation on a sample of Hindi audio files. It sources the audio from the Google FLEURS dataset on the Hugging Face Hub, saves local copies of the audio, and then creates text files containing both the Hindi transcript and the English translation.

-----

### \#\# 1. Libraries and Installation

This script uses several external Python libraries. You can install them by running the following commands in your terminal:

```powershell
pip install openai-whisper
pip install datasets
pip install torch
pip install numpy
pip install soundfile librosa
```

#### **What Each Library Does:**

  * **`os` & `shutil`:** Built-in Python libraries used for interacting with the file system, such as creating and deleting folders.
  * **`whisper` (`openai-whisper`):** The core library from OpenAI containing the multilingual model. It's used here for both transcribing speech into Hindi and translating it into English.
  * **`pathlib`:** A modern, built-in Python library for handling file and folder paths in a way that works reliably across different operating systems.
  * **`datasets`:** A library from Hugging Face that makes it easy to download and work with public datasets, including the Hindi audio samples used here.
  * **`soundfile`:** A helper library used to write the audio data from the dataset into a local `.wav` file.
  * **`numpy`:** A fundamental library for numerical computing. It's used to represent and manipulate the audio data as a numerical array before passing it to Whisper.

-----

### \#\# 2. Code Explanation

  * **Lines 1-9: Imports**

      * Imports the necessary libraries listed above.

  * **Lines 11-15: Configuration**

      * `AUDIO_DIR`: Defines the name of the folder where local copies of the audio files will be saved (`Audio_Hindi`).
      * `TRANSCRIPTS_DIR`: Sets the name of the folder where the final text transcripts will be saved (`transcripts_Hindi`).

  * **Lines 17-23: Setup**

      * The script first checks if the `transcripts_Hindi` folder exists from a previous run and deletes it to ensure a clean start.
      * It then creates both the audio and transcript folders if they don't already exist.

  * **Lines 26-28: Load Whisper Model**

      * `model = whisper.load_model("medium")`: This line downloads (the first time) and loads the multilingual `medium` version of the Whisper model into memory.

  * **Lines 31-36: Load Dataset**

      * This block connects to the Hugging Face Hub to download the Google FLEURS dataset.
      * `load_dataset("google/fleurs", "hi_in", ...)`: This specifies that we want the Hindi (`hi_in`) portion of the dataset.
      * `split="test[:5]"`: This efficiently loads only the first 5 audio samples for a quick test run.

  * **Lines 39-81: Main Processing Loop**

      * The script loops through each of the 5 downloaded audio samples.
      * **Lines 43-45:** Extracts the audio data and its sampling rate from the dataset sample.
      * **Lines 49-54:** Checks if a local copy of the audio file already exists in the `Audio_Hindi` folder. If not, it saves it as a `.wav` file.
      * **Line 57:** Converts the audio data into the specific `float32` numerical format that Whisper requires.
      * **Lines 60-62:** The first core task. The audio data is passed to `model.transcribe()` with `language="hi"` to get the Hindi text.
      * **Lines 65-67:** The second core task. The audio data is passed to `model.transcribe()` again, but this time with `task="translate"`, which tells the model to output English text.
      * **Lines 70-74:** Formats a string containing both the Hindi transcription and the English translation, separated by a line for clarity.
      * **Lines 77-80:** Saves the formatted string to a new `.txt` file in the `transcripts_Hindi` folder.

-----

### \#\# 3. Input Audio Source

  * **Source:** This script does not use your local files directly. It downloads 5 sample audio files from the **`google/fleurs`** dataset on the Hugging Face Hub.
  * **Local Copy:** It saves a copy of these downloaded files as `.wav` files in the **`Audio_Hindi`** folder for processing.

-----

### \#\# 4. Output Transcripts

  * **Folder:** The script creates and saves all transcripts in a folder named **`transcripts_Hindi`**.
  * **File Format:** Each transcript is saved as a separate `.txt` file, named sequentially (e.g., `hindi_transcript_0.txt`, `hindi_transcript_1.txt`, etc.).
  * **Content:** Each file contains both the Hindi transcription and the English translation generated by the Whisper model.