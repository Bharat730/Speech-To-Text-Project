### **Script Name: `STTdummydataset.py`**

This script is designed as a quick and efficient way to test a local Speech-to-Text setup. It uses OpenAI's Whisper model to transcribe a small, high-quality sample dataset downloaded from the Hugging Face Hub.

-----

### \#\# 1. Libraries and Installation

This script uses several external Python libraries. You can install them all by running the following commands in your terminal:

```powershell
pip install openai-whisper
pip install datasets
pip install torch
pip install numpy
pip install soundfile librosa
```

#### **What Each Library Does:**

  * **`whisper` (`openai-whisper`):** The core library from OpenAI that contains the powerful speech recognition model. It performs the actual transcription of audio to text.
  * **`datasets`:** A library from Hugging Face that makes it easy to download and work with thousands of datasets, including the audio dataset used in this script.
  * **`torch` (PyTorch):** A major machine learning framework that Whisper is built on. It handles all the underlying tensor calculations and neural network operations.
  * **`numpy`:** A fundamental library for numerical computing in Python. It's used to represent and manipulate the audio data, which is essentially a large array of numbers.
  * **`pathlib`:** A built-in Python library used to handle file and folder paths in a way that works reliably across different operating systems (like Windows, macOS, and Linux).
  * **`soundfile` & `librosa`:** Helper libraries for audio processing. The `datasets` library uses them in the background to read and decode different audio file formats.

-----

### \#\# 2. Code Explanation

  * **Lines 1-5: Imports**

      * Imports the necessary libraries listed above.

  * **Lines 13-18: Setup**

      * `device = "cpu"`: Configures the script to run on the CPU, as no dedicated GPU is assumed.
      * `output_directory = Path(...)`: Defines the name of the folder where the final text transcripts will be saved (`transcripts_dummy_test`).
      * `output_directory.mkdir(...)`: Creates this folder if it doesn't already exist.

  * **Lines 21-23: Load Whisper Model**

      * `model = whisper.load_model("medium", ...)`: This line downloads (the first time it's run) and loads the `medium` version of the Whisper model into memory. Subsequent runs will use the cached version.

  * **Lines 26-32: Load Dummy Dataset**

      * This block connects to the Hugging Face Hub to download a small sample dataset.
      * **Note:** The original dataset `hf-internal-testing/librispeech_asr_dummy` was removed. For the script to work, this should be changed to a working alternative like `patrickvonplaten/librispeech_asr_dummy`.
      * `split="validation"`: Specifies that we only want the small validation portion of the dataset.

  * **Lines 35-65: Main Processing Loop**

      * The script loops through each audio sample in the downloaded dataset.
      * **Lines 41-42:** Extracts the audio data (`array`) and the correct "ground truth" text (`text`) for comparison.
      * **Line 45:** Converts the audio data into the specific `float32` format that the Whisper model requires.
      * **Line 48:** The core transcription step. The audio data is passed to the `model.transcribe()` function, which returns the recognized text.
      * **Lines 51-55:** Formats a string that includes both the original, correct text (Reference) and the text generated by Whisper (Whisper Output).
      * **Lines 58-61:** Saves the formatted string to a new `.txt` file in the `transcripts_dummy_test` folder.

-----

### \#\# 3. Input Audio Source

  * **Source:** This script does not use a local folder. It directly downloads and uses a sample dataset from the **Hugging Face Hub**.
  * **Dataset Name:** `hf-internal-testing/librispeech_asr_dummy` (Note: This link may be broken; a working alternative is `patrickvonplaten/librispeech_asr_dummy`).

-----

### \#\# 4. Output Transcripts

  * **Folder:** The script creates and saves all transcripts in a folder named **`transcripts_dummy_test`**.
  * **File Format:** Each transcript is saved as a separate `.txt` file, named sequentially (e.g., `dummy_transcript_0.txt`, `dummy_transcript_1.txt`, etc.).
  * **Content:** Each file contains both the original reference text from the dataset and the new transcript generated by the Whisper model for comparison.